#LyX 2.4 created this file. For more info see https://www.lyx.org/
\lyxformat 620
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage{multicol}
\end_preamble
\use_default_options true
\maintain_unincluded_children no
\language american
\language_package default
\inputencoding utf8
\fontencoding auto
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_roman_osf false
\font_sans_osf false
\font_typewriter_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\float_placement class
\float_alignment class
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine natbib
\cite_engine_type authoryear
\biblio_style plainnat
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_formatted_ref 0
\use_minted 0
\use_lineno 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1cm
\topmargin 1cm
\rightmargin 1cm
\bottommargin 2cm
\headheight 1cm
\headsep 1cm
\footskip 1cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tablestyle default
\tracking_changes false
\output_changes false
\change_bars false
\postpone_fragile_content true
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\docbook_table_output 0
\docbook_mathml_prefix 1
\end_header

\begin_body

\begin_layout Title
From the column density to the volume density in molecular clouds using machine learning
\end_layout

\begin_layout Author
Zack Ribeiro
\begin_inset Foot
status open

\begin_layout Plain Layout
zackribeiro@univ-grenoble-alpes.fr
\end_layout

\end_inset


\end_layout

\begin_layout Abstract
/ code to easily train models and plot is available at 
\begin_inset CommandInset href
LatexCommand href
target "https://github.com/EazyEnder/KANion"

\end_inset

 (private for now)
\end_layout

\begin_layout Abstract
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Abstract
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Part
From the column density to the volume density using neural networks
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{multicols}{2}
\end_layout

\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
/ Hardest part to write...
 Why this is important,
 actual methods/tentatives,
 a bigger introduction on MC will be before Part I,
 at the beginning of the doc.
\end_layout

\begin_layout Subsection
Neural networks
\end_layout

\begin_layout Standard
Neural networks are machine learning models that process data through layers of interconnected neurons.
 Two key types are Multi-Layer Perceptrons (MLPs) and Convolutional Neural Networks (CNNs).
\end_layout

\begin_layout Itemize
MLPs are fully connected networks that apply weighted sums and non-linear activations.
 They work well for structured data but struggle with spatial dependencies.
\end_layout

\begin_layout Itemize
CNNs are designed for spatial data like images,
 using convolutional layers to extract features and pooling layers to reduce dimensionality (see Appendix 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Operations-used-CNN"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
\end_layout

\begin_layout Subsubsection
U-Net
\end_layout

\begin_layout Standard
U-Net 
\begin_inset CommandInset citation
LatexCommand citep
key "ronneberger_u-net_2015"
literal "false"

\end_inset

 is a specialized convolutional neural network architecture primarily designed for biomedical image segmentation.
 It features a symmetric encoder-decoder structure,
 where the encoder captures high-level features through convolution and max pooling operations,
 while the decoder gradually reconstructs the image using upsampling layers.
 A key feature of U-Net is its skip connections,
 which allow direct information flow between corresponding encoder and decoder layers,
 preserving spatial details lost during downsampling.
 (See Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:U-net-architecture"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

)
\end_layout

\begin_layout Standard
Even though it was originally designed for image segmentation,
 its ability to capture spatial information makes it suitable for our study of molecular clouds.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/unet_architecture.png
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
U-net architecture 
\begin_inset CommandInset citation
LatexCommand cite
key "ronneberger_u-net_2015"
literal "false"

\end_inset

 
\begin_inset CommandInset label
LatexCommand label
name "fig:U-net-architecture"

\end_inset

(example for 32x32 pixels in the lowest resolution).
 Each bluebox corresponds to a multi-channel feature map.
 The number of channels is denoted on top of the box.
 The x-y-size is provided at the lower left edge of the box.
 Whiteboxes represent copied feature maps.
 The arrows denote the different operations
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
KANs
\end_layout

\begin_layout Standard
Kolmogorov–Arnold Networks (KANs) 
\begin_inset CommandInset citation
LatexCommand citep
key "liu_kan_2024"
literal "false"

\end_inset

 are a novel class of neural networks inspired by the Kolmogorov–Arnold representation theorem.Unlike traditional deep learning architectures,
 KANs replace fixed activation functions with learnable,
 parameterized univariate functions (see Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:KAN"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 ).
 This design provides greater flexibility in function approximation while maintaining interpretability.
 KANs have demonstrated strong potential in various applications,
 including scientific computing and physics-informed learning,
 where explainability and efficient function representation are essential.
 However,
 they are more computationally expensive,
 and their interpretability is lost when incorporated into networks such as U-Net.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/kan_architecture.png
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Multi-Layer Perceptrons (MLPs) vs.
 Kolmogorov-Arnold Networks (KANs) 
\begin_inset CommandInset label
LatexCommand label
name "fig:KAN"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Method
\end_layout

\begin_layout Subsection
Datasets
\end_layout

\begin_layout Standard
In order to train our future model,
 two datasets are required:
 one for the training phase and the other for testing,
 i.e.,
 the validation phase.
 The preparation of these datasets is a crucial factor in the model's performance.
\end_layout

\begin_layout Standard
These datasets are created using MHD simulations of molecular clouds:
 ORION 
\begin_inset CommandInset citation
LatexCommand citep
key "ntormousi_core_2019"
literal "false"

\end_inset

.
 These simulations model MHD turbulence and have a size of 66.1 pc with an initial resolution of 0.01 pc,
 reaching a few hundred AU using an AMR grid.
 (Add details of the simu) However,
 to facilitate data manipulation,
 an initial approach consists of using a 
\begin_inset Formula $512^{3}$
\end_inset

 density cube.
 This cube has a width of 25.8 pc,
 centered at the simulation's midpoint,
 with a resolution of 
\begin_inset Formula $0.05$
\end_inset

 pc per pixel.
\end_layout

\begin_layout Standard
To increase the amount of training data,
 projections along the three axes are used.
 In other words,
 we generate three column density images by summing the densities along different axes as shown in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Column-density-for"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/orion_sim_faces.jpg
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Column density for 3 axes of the same molecular cloud from ORION
\begin_inset CommandInset citation
LatexCommand cite
key "ntormousi_core_2019"
literal "false"

\end_inset

 simulation,
 with low magnetic field 
\begin_inset CommandInset label
LatexCommand label
name "fig:Column-density-for"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Then,
 images with a resolution of 128×128 pixels and a physical size of 6.4 pc are randomly cropped from the three faces.
 An image is retained in the dataset if it meets several conditions:
\end_layout

\begin_layout Itemize
It is spatially distant enough from an already explored region,
 meaning it does not overlap with an area covered by an existing image.
\end_layout

\begin_layout Itemize
It does not contain a disproportionately large fraction of very low-density regions,
 i.e.,
 the edges of the simulation.
\end_layout

\begin_layout Itemize
It exhibits significant density variations within the explored region.
 A score is defined based on the smoothness of the image using the Laplacian of the density,
 favoring regions with filaments over those with nearly homogeneous density.
 (See appendix 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:How-the-score"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

)
\end_layout

\begin_layout Standard
The generated dataset is then randomly shuffled and split between training set (80%) and validation set (20%).
 For example,
 using only the simulation shown in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Column-density-for"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 we obtain a total of 37 covered regions,
 each represented by a pair of images:
 (column density,
 volume density).
 These are distributed as 29 training (pair of) images (78%) and 8 validation (pair of) images (22%).
 In subsection 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:U-Net-with-larger"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 a model will be trained with a larger dataset of 100 covered regions generated using the same ORION simulation but with a cube of 
\begin_inset Formula $1024^{3}$
\end_inset

 and so a resolution of 
\begin_inset Formula $0.026\text{pc per pixel}$
\end_inset

.
\end_layout

\begin_layout Standard
In this part,
 our goal is not to reconstruct the full density distribution along the line of sight,
 but rather to determine a single representative value for each region.
 There are several ways to compute such an average density,
 including:
\begin_inset Formula 
\begin{equation}
n_{V}=\frac{\sum_{i}^{N_{cells}}\Delta V_{i}n_{H,i}}{\sum_{i}^{N_{cells}}\Delta V_{i}}\overset{\Delta V=\text{cst}}{=}\frac{1}{N_{cells}}\sum_{i}^{N_{cells}}n_{H,i}\label{eq:volume_average_dens}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\Delta V_{i}$
\end_inset

 and 
\begin_inset Formula $n_{i}$
\end_inset

 are respectively the differential volume element and the number density of the ith cell.
 For an uniform grid,
 as in our initial approch,
 
\begin_inset Formula $\Delta V$
\end_inset

 is constant.
\end_layout

\begin_layout Standard
Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:volume_average_dens"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 is the volume-weighted density and has the problem that to get this,
 one need the cloud length.For our simulation,
 if we compute the volume-weighted density,
 we find that it simplifies to the column density 
\begin_inset Formula $N_{C}$
\end_inset

 divided by the box length 
\begin_inset Formula $L$
\end_inset

:
\begin_inset Formula 
\[
N_{C}=\sum_{i}n_{H,i}(\Delta V_{i})^{\frac{1}{3}}=N_{cells}(\Delta V)^{\frac{1}{3}}\sum_{i}n_{H,i}=L\sum_{i}n_{H,i}
\]

\end_inset


\end_layout

\begin_layout Standard
where we assume a uniform grid,
 but the principle remains valid even for a non-uniform grid.
 From this,
 we obtain:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
n_{V}=\frac{1}{N_{cells}}\sum_{i}^{N_{cells}}n_{H,i}=\frac{N_{C}}{L}
\]

\end_inset


\end_layout

\begin_layout Standard
This shows that the volume-weighted density computed on the simulation is directly proportional to the column density.
\end_layout

\begin_layout Standard
Another density which can be used is the mass-weighted average number density:
\begin_inset Formula 
\begin{equation}
n_{M}=\frac{\sum_{i}^{N_{cells}}m_{i}n_{H,i}}{\sum_{i}^{N_{cells}}m_{i}}\overset{\Delta V=\text{cst}}{=}\frac{\sum_{i}^{N_{cells}}n_{H,i}^{2}}{\sum_{i}^{N_{cells}}n_{H,i}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
This density highlights high density components along the line of sight.
 One can also use the max density along the l.o.s:
 
\begin_inset Formula $n_{\text{max}}=\text{max}(n_{i})$
\end_inset

 .
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/orion_sim_correlation.jpg
	width 80col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Density correlation of ORION
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/orion_sim_batch_ex.jpg
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Two examples from the ORION training dataset.
 Top row is the column density,
 bottom row is the mass-weighted density.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Network architecture
\end_layout

\begin_layout Standard
The default network architecture used in this part is a U-Net architecture with 4 layers,
 a first convolution layer which go from 1 to 64 features maps and attention blocks 
\begin_inset CommandInset citation
LatexCommand citep
key "oktay_attention_2018"
literal "false"

\end_inset

.
 The implementation of KAN in the architecture occurs at the output convolution layer,
 where the KAN layer replaces the classic convolution layer (named K-Net if that's the case),
 thanks to the work of X.
 Gao
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
target "https://github.com/XiangboGaoBarry/KA-Conv"
literal "false"

\end_inset


\end_layout

\end_inset

 on how to implement a convolution layer using KAN.
 The implementation is done in Python using PyTorch.
 It is also possible to only use KAN convolution layers instead of the classic ones.
\end_layout

\begin_layout Subsection
Training
\end_layout

\begin_layout Standard
Training a model is a crucial step in achieving good performance.
 There are multiple choices that we,
 as users,
 need to make to obtain optimal results.
\end_layout

\begin_layout Itemize
We want the model,
 with 
\begin_inset Formula $N$
\end_inset

 free parameters (weights),
 to converge to a global minimum of the loss function rather than getting stuck in a local well.
 Therefore,
 the choice of optimizer,
 which performs backward error propagation (adjusting the model’s weights),
 is important.
 Here,
 we use ADAM 
\begin_inset CommandInset citation
LatexCommand citep
key "kingma_adam_2017"
literal "false"

\end_inset

.
\end_layout

\begin_layout Itemize
Loss function:
 A well-chosen loss function is essential for accurately representing the problem.
 Here,
 we generally use MSELoss (see eq:
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:MSELoss"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

),
 but other loss methods can be considered.
\end_layout

\begin_layout Itemize
Learning rate:
 The learning rate is another critical factor—
it determines the step size the optimizer takes in the loss function during each update (epoch).
 Ideally,
 it should decrease when the loss reaches a plateau.
 To manage this,
 we use a scheduler.
 
\end_layout

\begin_layout Standard
Each epoch,
 i.e.,
 learning step,
 the model processes all the training batch
\begin_inset Foot
status open

\begin_layout Plain Layout
A batch is a set of paired images:
 column density/input & volume density/target
\end_layout

\end_inset

 column density images and predicts their mass-weighted density.
 
\end_layout

\begin_layout Standard
A way to artificially increase the size of the training batch is to apply random transformations to the images at each epoch 
\begin_inset CommandInset citation
LatexCommand citep
key "yang_image_2023"
literal "false"

\end_inset

,
 such as random rotations and random vertical or horizontal flips.
 Afterward,
 the prediction loss is computed using the chosen loss method,
 and backward error propagation is performed.
 Then,
 a new epoch begins,
 repeating the same steps.
\end_layout

\begin_layout Section
Model performance
\end_layout

\begin_layout Subsection
U-Net global performance 
\begin_inset CommandInset label
LatexCommand label
name "subsec:U-Net-global-performance"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/unet_validation_batch.jpg
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
U-Net prediction example,
 top row is the true mass-weighted density,
 bottom row is the predicted mass-weighted density.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
There are many ways to view if a model works or not.
 First,
 there are the losses,
 which are computed during training.
 Traditionally for regression problems,
 we use MSELoss ("Mean Squared Error") :
\begin_inset Formula 
\begin{equation}
\text{MSELoss}=\mathbb{E}((\text{prediction}-\text{target})^{2})\label{eq:MSELoss}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
In our case,
 this shows the mean squared error in log10 for the batch.
 In Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:U-Net-training-losses"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 the validation loss converges to ~0.25 and doesn't go lower.
 This could mean that the model cannot generalize more the training data due to a network that is too shallow or insufficient images in the training set.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/unet_losses.jpg
	width 90col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
U-Net training losses 
\begin_inset CommandInset label
LatexCommand label
name "fig:U-Net-training-losses"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
However,
 MSELoss is an average of all the batch errors.
 To analyze how the error varies as a function of density,
 we plot the correlation between the target and the predictions made by the trained model on the validation set (Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:U-Net-Prediction-correlation"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 An ideal result would be a correlation that is infinitely narrow along the 
\begin_inset Formula $y=x$
\end_inset

 line.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/unet_prediction_correlation.jpg
	width 80col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
U-Net Prediction correlation 
\begin_inset CommandInset label
LatexCommand label
name "fig:U-Net-Prediction-correlation"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Or,
 instead,
 we can directly analyze the residuals.
 This allows us to determine whether the model overestimates or underestimates lower or higher densities.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:U-Net-residuals"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 shows that U-Net tends to underestimate higher densities.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/unet_residuals.jpg
	width 80col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
U-Net residuals 
\begin_inset CommandInset label
LatexCommand label
name "fig:U-Net-residuals"

\end_inset

,
 Pixel value means in our case the mass-weighted density,
 blue is the residuals distribution in the density bin with black lines for min,max and mean of the residuals.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Molecular clouds form spatial structures such as cores and filaments,
 so it is also important to assess whether the spatial error is 
\begin_inset Quotes eld
\end_inset

homogeneous
\begin_inset Quotes erd
\end_inset

 (i.e.,
 does not exhibit obvious structures—
see Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:U-Net-Validation-spatial"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 for example) or if the model struggles to predict certain features,
 such as densities within a filament.
 If this is the case,
 an alternative loss function that emphasizes spatial structures could improve the model's performance.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/unet_validation_spatial_error.jpg
	lyxscale 50
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
U-Net Validation spatial errors 
\begin_inset CommandInset label
LatexCommand label
name "fig:U-Net-Validation-spatial"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Finally,
 we can also define an error metric that we will refer to as "accuracy." The accuracy of the predicted image is the ratio of correct predictions to the total number of elements (i.e.,
 pixels,
 here 
\begin_inset Formula $128\times128$
\end_inset

).
 A predicted pixel is considered correct if
\begin_inset Formula $|\text{target}-\text{prediction}|<\sigma$
\end_inset

 ,where 
\begin_inset Formula $\sigma$
\end_inset

 represents the allowed error in the prediction in log10.
\begin_inset Formula 
\begin{equation}
Acc_{i}=\frac{\sum_{i}^{N_{pixels}}N(|\text{target}-\text{prediction}|<\sigma)}{N_{pixels}}\label{eq:Accuracy}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
And for the entire validation batch,
 the accuracy is computed as the average accuracy across all images in the batch.
\begin_inset Formula 
\begin{equation}
Acc=<Acc_{i}>_{\text{batch}}=\frac{1}{B}\sum_{i}^{B}Acc_{i}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $B$
\end_inset

 is the batch size,i.e the number of images in the batch.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/unet_accuracy.jpg
	lyxscale 50
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
U-Net Accuracy.
 Transparent area is the standard deviation of the accuracy over the batch images.
 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
U-Net complexity 
\end_layout

\begin_layout Standard
Our problem is a regression problem,
 similar to function fitting.
 As with function fitting,
 our model has 
\begin_inset Formula $N$
\end_inset

 free parameters.
 A higher 
\begin_inset Formula $N$
\end_inset

 increases the likelihood of capturing important features,
 whereas a lower 
\begin_inset Formula $N$
\end_inset

 may lead to missing details such as high-frequency variations or structural connections.
\end_layout

\begin_layout Standard
In the U-Net architecture,
 the number of free parameters is influenced by:
\end_layout

\begin_layout Itemize
The number of layers:
 This determines how many times the network applies pooling,
 affecting the depth of feature extraction.
\end_layout

\begin_layout Itemize
The base filters:
 The first convolutional layer creates 
\begin_inset Formula $n$
\end_inset

 feature maps from the input (column density),
 i.e.
 
\begin_inset Formula $1\rightarrow n$
\end_inset

.
 Then,
 each subsequent layer and its convolutional operations generally double this number.
 For example,
 a convolutional layer in the 
\begin_inset Formula $i$
\end_inset

th U-Net encoder stage transforms 
\begin_inset Formula $n\times2^{i-1}$
\end_inset

 feature maps into 
\begin_inset Formula $n\times2^{i}$
\end_inset

.
\end_layout

\begin_layout Standard
So,
 when the number of base filters or the number of layers increases,
 we say that the model complexity increases.
 And generally,
 as the complexity increases,
 the memory usage,
 training time,
 and the number of epochs required to converge to a validation plateau will also be higher.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/unet_compmap.jpg
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
U-Net complexity map 
\begin_inset CommandInset label
LatexCommand label
name "fig:U-Net-complexity-map"

\end_inset

.
 Each point is a trained U-Net with attention blocks and with X Base Filters and Y Layers.
 Yellow means higher accuracy and purple lower accuracy.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:U-Net-complexity-map"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 shows the variation of the model accuracy 
\begin_inset Formula $Acc$
\end_inset

 with the number of base filters and the number of layers.
 This highlights that a model with higher complexity does not always guarantee better accuracy,
 probably because of the lack of training data and longer convergence time.
 However,
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:U-Net-complexity-map"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 is not sufficient because the accuracy,
 as defined by 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:Accuracy"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 can be higher even for a blurred prediction.
 This is illustrated in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:U-Net-2-layers"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 where a model with fewer layers fails to capture high-frequency features (sharp edges),
 resulting in a blurry output.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/unet_compmap_l2bf80_validation.jpg
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
U-Net 2 layers with 80 initial features maps,
 validation images.
 Top row is the true mass-weighted density,
 bottom row is the predicted mass-weighted density.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:U-Net-2-layers"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Note that in U-Net,
 each layer typically performs two convolution operations rather than just one,
 as shown in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:U-net-architecture"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 This further increases the model complexity.
 However,
 in our case,
 using two convolutions per block does not lead to better performance (see figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:U-Net-DoubleConv"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
 Therefore,
 our default model is designed with just one convolution operation per block to reduce computational cost while maintaining accuracy.
 That said,
 our implementation is flexible,
 making it easy to modify the architecture and use alternative blocks,
 such as double convolution per block,
 if needed.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="1" columns="2">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "50col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "foreground"
backgroundcolor "none"
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/unet_double_accuracy.jpg
	width 100col%

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "50col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "foreground"
backgroundcolor "none"
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/unet_double_residuals.jpg
	width 100col%

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
U-Net Accuracy and Residuals for double conv per block (black) and for one conv per block (green) 
\begin_inset CommandInset label
LatexCommand label
name "fig:U-Net-DoubleConv"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
U-Net with KAN parts (TODO)
\end_layout

\begin_layout Standard
Kolmogorov Arnold Networks
\begin_inset CommandInset citation
LatexCommand citep
key "liu_kan_2024"
literal "false"

\end_inset

 are news and promising alternatives of MLPs.
 They replace fixed activation functions with learnable sum of univariates functions like B-splines or Radial Basis functions 
\begin_inset CommandInset citation
LatexCommand citep
key "li_kolmogorov-arnold_2024"
literal "false"

\end_inset

.
 Some recent papers have shown that using KAN layers in traditional architectures can improve performance and accuracy 
\begin_inset CommandInset citation
LatexCommand citep
key "li_u-kan_2024"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Subsubsection
KAN Layer as an network convolutionnal output
\end_layout

\begin_layout Standard
Our first idea is to simply replace the output convolutionnal layer of U-Net by a KAN convolutionnal layer,
 creating a new architecture referred to as “K-Net”.
 The goal is to evaluate whether the KAN layer improves training when the network has more layers.
\end_layout

\begin_layout Standard
Since KAN layers are more computationally expensive,
 training takes longer.
 However,
 replacing only one layer keeps the training time per epoch manageable,
 allowing us to analyze the complexity map (Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:K-Net-complexity-map"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

).
\end_layout

\begin_layout Standard
The results show that K-Net's accuracy is slightly lower than U-Net's,
 and the same trend persists:
 accuracy decreases as the number of layers increases.
 Thus,
 this small modification does not provide significant benefits over the standard U-Net architecture.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/knet_compmap.jpg
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
K-Net complexity map 
\begin_inset CommandInset label
LatexCommand label
name "fig:K-Net-complexity-map"

\end_inset

.
 Each point is a trained U-Net with KAN conv output with attention blocks and with X Base Filters and Y Layers.
 Yellow means higher accuracy and purple lower accuracy.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
KAN Layer as a symbolic use 
\end_layout

\begin_layout Standard
Another approach is to fit the function 
\begin_inset Formula $N_{col}(n_{H})$
\end_inset

 using a KAN layer that operates on the flattened image matrix—
that is,
 with one number input (the column density) and one number output (the number density).
 In parallel,
 a U-Net network can be used to incorporate spatial information.
 
\end_layout

\begin_layout Subsubsection
KAN Layer as a replacement of convolutionnal layers
\end_layout

\begin_layout Subsection
U-Net working scale
\begin_inset CommandInset label
LatexCommand label
name "subsec:U-Net-with-larger"

\end_inset


\end_layout

\begin_layout Standard
Real observations and derived column density maps span a large range of sizes,
 such as the Herschel column density map of Taurus B213,
 which will be seen in the next section and is a few parsecs long.
 However,
 our model is trained on a single large scale of approximately 6 pc (width of the 
\begin_inset Formula $128\times128$
\end_inset

 image).
 Therefore,
 to apply our model to observed maps,
 we train a U-Net model on a dataset generated from the same simulation but at a higher resolution:
 
\begin_inset Formula $1024^{3}$
\end_inset

 instead of 
\begin_inset Formula $512^{3}$
\end_inset

.
 Thus,
 no physical parameters are changed—
only the working resolution of the model is improved,
 from 0.05pc per pixel to 0.025pc per pixel.
 This new dataset contains 
\begin_inset Formula $100$
\end_inset

 pairs of images instead of the previously 
\begin_inset Formula $37$
\end_inset

.
 Therefore,
 the previously discussed trends regarding model complexity and performance remain unchanged.
 While a higher-resolution dataset provides more detailed information,
 the relationship between model capacity,
 accuracy,
 and computational cost follows the same principles.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="1" columns="2">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "50col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "foreground"
backgroundcolor "none"
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/unet_highres_accuracy.jpg
	width 100col%

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "50col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "foreground"
backgroundcolor "none"
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/unet_highres_residuals.jpg
	width 100col%

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
U-Net Accuracy and Residuals on a high resolution validation set for a model trained on this set (green) and the previous model(black) 
\begin_inset CommandInset label
LatexCommand label
name "fig:U-Net-HighRes"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
As we can see in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:U-Net-HighRes"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 the model previously trained at a lower resolution performs worse than a U-Net model trained at this new resolution.
 Even though the residuals span a wider range of values,
 the majority of the residuals distribution remains centered around 0.0.
\end_layout

\begin_layout Standard
We can conclude that,
 to make an accurate prediction for an observation of a certain spatial size,
 the model must have been trained on that specific size.
 Otherwise,
 it is necessary to downsample the observation map before applying the prediction.
\end_layout

\begin_layout Section
Results
\end_layout

\begin_layout Standard
In this section,
 we apply our basic U-Net model to Herschel observations,
 allowing us to compare it with a few recent methods:
\end_layout

\begin_layout Itemize
A machine learning approach 
\begin_inset CommandInset citation
LatexCommand citep
key "xu_denoising_2023"
literal "false"

\end_inset

 that uses a Denoising Diffusion Probabilistic Model to predict molecular cloud number density.
\end_layout

\begin_layout Itemize
A method based on fitting the log-PDF of the column density combined with a probabilistic model 
\begin_inset CommandInset citation
LatexCommand citep
key "gaches_probabilistic_2024"
literal "false"

\end_inset

.
\end_layout

\begin_layout Itemize
A novel inverse modeling approach 
\begin_inset CommandInset citation
LatexCommand citep
key "orkisz_volume_2024"
literal "false"

\end_inset

.
\end_layout

\begin_layout Subsection
Taurus L1495
\end_layout

\begin_layout Standard
The Herschel column density map of Taurus L1495,
 one of the closest star-forming filamentary structures,
 is obtained from 
\begin_inset CommandInset citation
LatexCommand citet
key "palmeirim_herschel_2013"
literal "false"

\end_inset

 with a resolution of 18.2".
 The column density map is derived based on an optically thin graybody assumption.
 By adopting a power-law radial density profile to fit the column density,
 they found the central density of the filament to be 
\begin_inset Formula $n_{H,c}=7.5\times10^{4}cm^{-3}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/obs_taurusl1495_columndensity.jpg
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Taurus L1495 Column density
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand citet
key "xu_denoising_2023"
literal "false"

\end_inset

 predicted a line of sight mass-weighted number density of 
\begin_inset Formula $4.7\times10^{4}cm^{-3}$
\end_inset

.
 
\begin_inset CommandInset citation
LatexCommand citet
key "gaches_probabilistic_2024"
literal "false"

\end_inset

 on the other hand,
 predicted a density of 
\begin_inset Formula $2\times10^{3}cm^{-3}$
\end_inset

 for diffuse regions and 
\begin_inset Formula $10^{5}cm^{-3}$
\end_inset

 for dense regions,
 such as the filament core.
 Not to mention 
\begin_inset CommandInset citation
LatexCommand citet
key "li_is_2012"
literal "false"

\end_inset

,
 who,
 by using cyanoacetylene transitions,
 measured an average volume density of 
\begin_inset Formula $1.8\times10^{4}cm^{-3}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/obs_taurusl1495_volumedensity.jpg
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Taurus L1495 Predicted mass-weighted density 
\begin_inset CommandInset label
LatexCommand label
name "fig:Taurus-L1495-Predicted"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Our prediction is shown in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Taurus-L1495-Predicted"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
 We predict a maximum mass-weighted density of 
\begin_inset Formula $1.5\times10^{4}cm^{-3}$
\end_inset

,
 with diffuse regions ranging between 
\begin_inset Formula $0.5\times10^{2}cm^{-3}$
\end_inset

 and 
\begin_inset Formula $1.2\times10^{2}cm^{-3}$
\end_inset

(corresponding to the 50% and 95% quantiles,
 respectively).
 The correlation between number density and column density is shown in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Taurus-L1495-Correlation"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/obs_taurusl1495_correlation.jpg
	width 80col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Taurus L1495 Correlation for the Predicted mass-weighted density 
\begin_inset CommandInset label
LatexCommand label
name "fig:Taurus-L1495-Correlation"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Our prediction is lower than previous estimates,
 likely even when accounting for the fact that we predict a mass-weighted average rather than the maximum along the line of sight.
 This difference may be due to an underestimation of high densities,
 as highlighted in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:U-Net-global-performance"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

.
\end_layout

\begin_layout Subsection
Polaris Flare
\end_layout

\begin_layout Standard
The Polaris Flare is a diffuse cloud that exhibits little to no signs of ongoing star formation,
 making it a quiescent star-forming region.
 However,
 
\begin_inset CommandInset citation
LatexCommand citet
key "ward-thompson_herschel_2010"
literal "false"

\end_inset

 identified five possibly bound prestellar cores within the 
\begin_inset Quotes eld
\end_inset

saxophone
\begin_inset Quotes erd
\end_inset

 region with a mean density of 
\begin_inset Formula $n_{H_{2},c}=5\times10^{4}cm^{-3}$
\end_inset

 and a mean radius near 
\begin_inset Formula $0.03\text{pc}$
\end_inset

.
 The Polaris Flare is characterized by diffuse gaseous structures and striations,
 with a strong magnetic field threading the cloud 
\begin_inset CommandInset citation
LatexCommand citep
key "panopoulou_magnetic_2016"
literal "false"

\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/obs_polaris_columndensity.jpg
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Polaris Flare Column density
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Using their probabilistic method,
 
\begin_inset CommandInset citation
LatexCommand citet
key "gaches_probabilistic_2024"
literal "false"

\end_inset

 found a diffuse density of 
\begin_inset Formula $n_{H,\text{diffuse}}\sim10^{2}cm^{-3}$
\end_inset

 and a dense density 
\begin_inset Formula $n_{H,\text{dense}}$
\end_inset

 reaching up to a few 
\begin_inset Formula $10³cm^{-3}$
\end_inset

.
 Our model prediction,
 shown in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Polaris-Predicted"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

,
 gives a mean diffuse density of 
\begin_inset Formula $n_{H}=3\times10^{1}cm^{-3}$
\end_inset

 and a maximum mass-weighted density of 
\begin_inset Formula $n_{H}=3\times10^{2}cm^{-3}$
\end_inset

 in the 
\begin_inset Quotes eld
\end_inset

saxophone
\begin_inset Quotes erd
\end_inset

 region.
 This suggests our prediction is an order of magnitude lower for the diffuse region and likely several orders lower for the saxophone region,
 where our basic model don't show any massive cores.
 This could be due to a lack of diversity in the training dataset,
 i.e.,
 the absence of training data featuring a strong magnetic field and/or physical properties similar to those of the Polaris Flare cloud.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/obs_polaris_volumedensity.jpg
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Polaris Flare Predicted mass-weighted density 
\begin_inset CommandInset label
LatexCommand label
name "fig:Polaris-Predicted"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
https://www.aanda.org/articles/aa/pdf/2010/10/aa14618-10.pdf <- coeurs denses dans polaris,
 pourquoi pas rajouter la température dans le model ?
 Faire un zoom sur le saxo avec les coeurs denses en highlight
\end_layout

\begin_layout Subsection
Orion A
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/obs_oriona_columndensity.jpg
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Orion A Column density
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/obs_oriona_volumedensity.jpg
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Orion A Predicted mass-weighted density 
\begin_inset CommandInset label
LatexCommand label
name "fig:OrionA-Predicted-1"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{multicols}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/obs_oriona_volumedensity_zoom.jpg
	width 80col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Orion A,
 Zoom on Predicted mass-weighted density
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{multicols}{2}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{multicols}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Part
From the p-p-v space to the p-p-p space
\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{multicols}{2}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "biblio"
options "plainnat"
encoding "default"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{multicols}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
\start_of_appendix
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{multicols}{2}
\end_layout

\end_inset


\end_layout

\begin_layout Section
Operations used in U-Net 
\begin_inset CommandInset label
LatexCommand label
name "sec:Operations-used-CNN"

\end_inset


\end_layout

\begin_layout Standard
The U-Net 
\begin_inset CommandInset citation
LatexCommand cite
key "ronneberger_u-net_2015"
literal "false"

\end_inset

 architecture (see figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:U-net-architecture"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

) is built upon a combination of a few basic operations.
 To fully grasp how the network functions and later adapt it to our specific problem,
 it is crucial to understand these operations.
\end_layout

\begin_layout Standard
Since these operations are already implemented and optimized in popular libraries like PyTorch,
 it is easy to fall into the trap of constructing an architecture without understanding its underlying mechanics.
\end_layout

\begin_layout Subsection
Convolution
\end_layout

\begin_layout Standard
Convolution is the fundamental operation in deep learning architectures like U-Net.
 It applies a set of 
\begin_inset Formula $N$
\end_inset

 learnable filters (learnable kernels) to an input image,
 extracting features such as edges and patterns.
 Each filter slides across the image,
 computing weighted sums to create 
\begin_inset Formula $N$
\end_inset

 feature maps,
 which are then passed to the next layers.
 (see note for image author & details 
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
target "https://www.geeksforgeeks.org/apply-a-2d-convolution-operation-in-pytorch/"

\end_inset


\end_layout

\end_inset

)
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/unet_op_conv.png
	lyxscale 50
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Network Convolution
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Max pooling
\end_layout

\begin_layout Standard
Max pooling is a downsampling operation used to reduce the spatial dimensions of feature maps while preserving the most important information.
 It works by selecting the maximum value from a small region (e.g.,
 2×2) of the feature map,
 improving computational efficiency and making the network more robust to small spatial variations.
 
\end_layout

\begin_layout Standard
It is also possible to use other pooling operations,
 such as Average Pooling,
 where instead of selecting the maximum value in a region,
 the average of all values is taken.
 However,
 Average Pooling is generally less efficient in capturing important features because it smooths out details,
 whereas Max Pooling preserves the most prominent features by selecting the highest value.
 (see note for image author & details
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
target "https://www.geeksforgeeks.org/apply-a-2d-max-pooling-in-pytorch/"

\end_inset


\end_layout

\end_inset

)
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/unet_op_maxpooling.png
	lyxscale 50
	width 85col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Network Max Pooling
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Conv Transpose
\end_layout

\begin_layout Standard
Also known as upsampling convolution,
 this operation increases the spatial dimensions of feature maps.
 It is used in the U-Net decoder to reconstruct high-resolution outputs from lower-resolution feature maps,
 helping to recover lost spatial details.
 (see note for image author & details
\begin_inset Foot
status open

\begin_layout Plain Layout
\begin_inset CommandInset href
LatexCommand href
target "https://www.geeksforgeeks.org/what-is-transposed-convolutional-layer/"

\end_inset


\end_layout

\end_inset

)
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/unet_op_convtrans.png
	lyxscale 50
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Network Convolutionnal Transpose
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Concatenate
\end_layout

\begin_layout Standard
Concatenation is a key operation in U-Net,
 allowing feature maps from different layers to be combined.
 In the skip connections,
 feature maps from the encoder are concatenated with corresponding decoder layers,
 ensuring that fine spatial information is retained during reconstruction.
\end_layout

\begin_layout Subsection
ReLU
\end_layout

\begin_layout Standard
ReLU is an activation function applied after convolution to introduce non-linearity.
 It sets negative values to zero while keeping positive values unchanged:
\begin_inset Formula 
\begin{equation}
\text{ReLU}(x)=\text{max}(0,x)
\end{equation}

\end_inset

Which helps accelerate training and prevent the vanishing gradient problem.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{multicols}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{multicols}{2}
\end_layout

\end_inset


\end_layout

\begin_layout Section
How the score is computed 
\begin_inset CommandInset label
LatexCommand label
name "sec:How-the-score"

\end_inset


\end_layout

\begin_layout Standard
Creating a training dataset is a crucial step in building an effective model.
 In our case,
 we want to avoid overtraining on the borders of the simulation,
 as these regions contain less valuable information compared to the dense regions with filaments and cores.
\end_layout

\begin_layout Standard
To achieve this,
 we implement an additional filtering step:
\end_layout

\begin_layout Enumerate
We compute a "score" 
\begin_inset Formula $s(\text{image})$
\end_inset

 for each new candidate area before adding it to the dataset.
\end_layout

\begin_layout Enumerate
This score is calculated using a custom function that aligns with our training objectives.
\end_layout

\begin_layout Enumerate
We then apply a filter function 
\begin_inset Formula $f(s)$
\end_inset

.
 If a randomly generated number (
\begin_inset Formula $random$
\end_inset

) in the range [0,1] satisfies 
\begin_inset Formula $random<f(s)$
\end_inset

,
 the region is accepted and added to the training set.
 I.e 
\begin_inset Formula $f(s)$
\end_inset

 is the probability to accept and add an area with a score of 
\begin_inset Formula $s$
\end_inset

 in the dataset.
 
\end_layout

\begin_layout Standard
This approach ensures that the dataset focuses more on important structures (filaments and cores) rather than sparse or less informative regions.
 
\end_layout

\begin_layout Standard
We can also use multiple scoring functions,
 each capturing different aspects of the dataset,
 and combine them using weighted (
\begin_inset Formula $w_{i}$
\end_inset

) sums to account for various criteria.
 Mathematically,
 the final score 
\begin_inset Formula $s$
\end_inset

 can be expressed as:
\begin_inset Formula 
\begin{equation}
s=\sum_{i}s_{i}w_{i}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
This score can also be made for the column density image 
\begin_inset Formula $s(N_{C})$
\end_inset

 and the volume density image 
\begin_inset Formula $s(n_{H})$
\end_inset

.
\end_layout

\begin_layout Subsection
Smoothness score
\end_layout

\begin_layout Standard
The score function used when generating our training set needs to be based on the smoothness of the selected area.
 This is because if an area is entirely within a diffuse region,
 it will exhibit low spatial frequency variation (i.e.,
 only large-scale structures) and lack filaments.
\end_layout

\begin_layout Standard
To ensure that each selected image contains both diffuse regions and some filaments,
 we use the variance of the smoothness as a criterion.
 The smoothness itself is defined as the Laplacian of the image,
 which highlights areas with sharp density changes (such as filaments).
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
s_{\Delta}(x)=\text{Var}[\Delta(\log(1+x)-\min[\log(1+x)])]\label{eq:score_lapl}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The variance in equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:score_lapl"
plural "false"
caps "false"
noprefix "false"
nolink "false"

\end_inset

 is to get a mix of dense and high-density regions.
\end_layout

\begin_layout Subsection
Difference score
\end_layout

\begin_layout Standard
A basic criterion that can be chosen is the difference between the normalized column density and the normalized volume density.
 This helps identify regions where the local density distribution differs significantly between the two representations.
\end_layout

\begin_layout Standard
For example,
 when using mass-weighted density,
 this criterion will highlight dense regions,
 since areas with high volume density but relatively lower column density indicate localized dense structures along the l.o.s.
\begin_inset Formula 
\begin{equation}
s_{\text{res}}=\text{Var}[\frac{N_{C}-\min(N_{C})}{\max(N_{C})-\text{min}(N_{C})}-\frac{n_{H}-\min(n_{H})}{\max(n_{H})-\min(n_{H})}]
\end{equation}

\end_inset


\end_layout

\begin_layout Subsection
Filter function
\end_layout

\begin_layout Standard
As a filter function 
\begin_inset Formula $f(s)$
\end_inset

,
 we use a sigmoid :
 
\begin_inset Formula 
\begin{equation}
f(s)=\frac{1}{1+\exp(-A(s-B))}
\end{equation}

\end_inset

 where 
\begin_inset Formula $\begin{cases}
A: & \text{step length}\\
B: & \text{offset}
\end{cases}$
\end_inset

 and are chosen empirically.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
alignment document
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figure/sigmoid.jpg
	lyxscale 50
	width 75col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Sigmoid as a filter function
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{multicols}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{multicols}{2}
\end_layout

\end_inset


\end_layout

\begin_layout Section
Prediction of the density maximum along the line of sight
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{multicols}
\end_layout

\end_inset


\end_layout

\end_body
\end_document
